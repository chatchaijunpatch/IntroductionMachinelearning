{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ชัชชาย จันทร์เพ็ชร์ 6210450059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of the data samples \n",
      "   Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina... \n",
      "\n",
      "Dimension of the data set:\n",
      " (5572, 2) \n",
      "\n",
      "Distribution of the data set:\n",
      " ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Label, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sms_spam_data_set = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "print(\"Examples of the data samples \\n\", sms_spam_data_set.head(3), \"\\n\")\n",
    "print(\"Dimension of the data set:\\n\", sms_spam_data_set.shape, \"\\n\")\n",
    "print(\"Distribution of the data set:\\n\", sms_spam_data_set['Label'].value_counts(normalize=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribtuion of the training data set:\n",
      " ham     0.866726\n",
      "spam    0.133274\n",
      "Name: Label, dtype: float64 4457 \n",
      "\n",
      "Distribtuion of the testing data set:\n",
      " ham     0.86278\n",
      "spam    0.13722\n",
      "Name: Label, dtype: float64 1115 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform train/test split\n",
    "sms_texts, labels = sms_spam_data_set.SMS, sms_spam_data_set.Label\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "sms_texts_train, sms_texts_test, labels_train, labels_test = train_test_split(sms_texts, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "sms_texts_train = sms_texts_train.reset_index(drop=True)\n",
    "labels_train = labels_train.reset_index(drop=True)\n",
    "\n",
    "sms_texts_test = sms_texts_test.reset_index(drop=True)\n",
    "labels_test = labels_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Distribtuion of the training data set:\\n\", labels_train.value_counts(normalize=True),  labels_train.shape[0], \"\\n\")\n",
    "\n",
    "print(\"Distribtuion of the testing data set:\\n\", labels_test.value_counts(normalize=True), labels_test.shape[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-10209bae6ee5>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sms_texts = sms_texts.str.replace('\\W', ' ') #Remove punctuation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (the number of all possible words in the trainning data):\n",
      " 7732 \n",
      "\n",
      "Examples of the training data \n",
      "   Label                                                SMS  cliffs  beerage  \\\n",
      "0  spam  Double mins and txts 4 6months FREE Bluetooth ...       0        0   \n",
      "1   ham  Did you get any gift? This year i didnt get an...       0        0   \n",
      "2   ham  Ever green quote ever told by Jerry in cartoon...       0        0   \n",
      "\n",
      "   goodmorning  congratulations  ihave  mel  clarify  set  ...  lei  \\\n",
      "0            0                0      0    0        0    0  ...    0   \n",
      "1            0                0      0    0        0    0  ...    0   \n",
      "2            0                0      0    0        0    0  ...    0   \n",
      "\n",
      "   4403ldnw1a7rw18  imprtant  install  lik  tease  evenings  dump  purchase  \\\n",
      "0                0         0        0    0      0         0     0         0   \n",
      "1                0         0        0    0      0         0     0         0   \n",
      "2                0         0        0    0      0         0     0         0   \n",
      "\n",
      "   80086  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 7734 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function to convert input sms texts to feature vectors using BoW representation\n",
    "def smsTextsToVectors(sms_texts):\n",
    "    sms_texts = sms_texts.str.replace('\\W', ' ') #Remove punctuation\n",
    "    sms_texts = sms_texts.str.lower()\n",
    "    sms_texts = sms_texts.str.split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for sms in sms_texts:\n",
    "        for word in sms:\n",
    "            vocabulary.append(word)\n",
    "        \n",
    "    vocabulary = list(set(vocabulary))\n",
    "    \n",
    "    word_counts_per_sms = {unique_word: [0] * len(sms_texts) for unique_word in vocabulary}\n",
    "    \n",
    "    for index, sms in enumerate(sms_texts):\n",
    "        for word in sms:\n",
    "            word_counts_per_sms[word][index] += 1\n",
    "            \n",
    "    return word_counts_per_sms, vocabulary\n",
    "\n",
    "word_counts_per_sms, vocabulary  = smsTextsToVectors(sms_texts_train) \n",
    "x_train = pd.DataFrame(word_counts_per_sms)\n",
    "print(\"Features (the number of all possible words in the trainning data):\\n\", len(vocabulary), \"\\n\")\n",
    "\n",
    "training_data_set = pd.concat([labels_train, sms_texts_train, x_train], axis=1)\n",
    "print(\"Examples of the training data \\n\", training_data_set.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our estimate of P(y=spam) is  0.13327350235584473\n",
      "Our estimate of P(y=ham) is  0.8667264976441552\n"
     ]
    }
   ],
   "source": [
    "x_train_spam = x_train[labels_train == 'spam']\n",
    "x_train_ham = x_train[labels_train == 'ham']\n",
    "\n",
    "#Estimate P(y=spam) and P(y=ham)\n",
    "p_spam = len(x_train_spam)/len(x_train)\n",
    "print(\"Our estimate of P(y=spam) is \", p_spam)\n",
    "\n",
    "p_ham = len(x_train_ham)/len(x_train)\n",
    "print(\"Our estimate of P(y=ham) is \", p_ham)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate parameters\n",
    "theta_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "theta_ham =  {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "#Estimate the probability distribution of selecting each word\n",
    "# uncomment to implement the following\n",
    "m_spam=0\n",
    "m_ham = 0\n",
    "\n",
    "for word in vocabulary:\n",
    "    m_spam = m_spam + sum(x_train_spam[word])\n",
    "    m_ham = m_ham + sum(x_train_ham[word])\n",
    "\n",
    "for word in vocabulary:\n",
    "    # uncomment to implement the following\n",
    "    theta_spam[word] = sum(x_train_spam[word])/m_spam\n",
    "    \n",
    "    # uncomment to implement the following\n",
    "    theta_ham[word] = sum(x_train_ham[word])/m_ham\n",
    "    #MAP check whether on data-train has frequence 0 so we can assume confidence value\n",
    "    if(theta_spam[word] ==0):\n",
    "        theta_spam[word] = 1/(m_spam+m_ham)\n",
    "    if(theta_ham[word]==0):\n",
    "        theta_ham[word] = 1/(m_ham+m_spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implment Naive Bayes classifier\n",
    "import re, math\n",
    "def textToVector(message):\n",
    "    message = re.sub('\\W', ' ', message) #Remove punctuation\n",
    "    message = message.lower().split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for word in  message:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "    vocabulary = list(set(vocabulary))\n",
    "    \n",
    "    word_counts = {unique_word: 0 for unique_word in vocabulary}\n",
    "    \n",
    "    for word in message:\n",
    "            word_counts[word] += 1\n",
    "            \n",
    "    return word_counts, vocabulary\n",
    "\n",
    "def naive_bayes_classify(sms_text):\n",
    "    x_test, vocabulary_test = textToVector(sms_text)\n",
    "    #Navie Bayes Classification \n",
    "    p_spam_given_sms = np.log(p_spam)\n",
    "    p_ham_given_sms = np.log(p_ham)\n",
    "    for word in vocabulary_test:\n",
    "        if(word in (theta_spam)):\n",
    "            p_spam_given_sms += (x_test[word]*np.log(theta_spam[word]))\n",
    "        else:\n",
    "            p_spam_given_sms +=  (x_test[word]*np.log(1/(m_spam+m_ham))) #MAP condition when there no word in data train\n",
    "\n",
    "        if (word in (theta_ham)):\n",
    "            p_ham_given_sms += (x_test[word]*np.log(theta_ham[word]))\n",
    "        else:\n",
    "             p_ham_given_sms +=  (x_test[word]*np.log(1/(m_ham+m_spam))) #MAP condition when there no word in data train\n",
    "#     uncomment to implement the following\n",
    "\n",
    "    isSpam = True\n",
    "    if(p_spam_given_sms > p_ham_given_sms):\n",
    "        isSpam = True\n",
    "    else:\n",
    "        isSpam = False\n",
    "    return isSpam\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(naive_bayes_classify(\"WINNER!! This is the secret code to unlock the money: C3421.\"))\n",
    "print(naive_bayes_classify(\"Sounds good, Tom, then u there\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(sms_texts, labels):\n",
    "    mistakes = 0\n",
    "    for i, message in enumerate(sms_texts):\n",
    "        isSpam = naive_bayes_classify(message)\n",
    "        if isSpam and labels[i] != \"spam\":\n",
    "            mistakes += 1\n",
    "        elif not isSpam and labels[i] == \"spam\":\n",
    "            mistakes += 1\n",
    "    return (len(sms_texts)-mistakes)/len(sms_texts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9946152120260264\n",
      "Generalization accuracy: 0.9847533632286996\n"
     ]
    }
   ],
   "source": [
    "#Calculate loss on training data\n",
    "print(\"Training accuracy:\", score(sms_texts_train, labels_train))\n",
    "#Calculate generalization loss\n",
    "print(\"Generalization accuracy:\", score(sms_texts_test, labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's spam\n"
     ]
    }
   ],
   "source": [
    "print(\"It's spam\" if naive_bayes_classify(\"Click here for more info\") else \"It's ham\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
