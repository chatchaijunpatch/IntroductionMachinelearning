{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ชัชชาย จันทร์เพ็ชร์ 6210450059"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "sms_spam_data_set = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\r\n",
    "print(\"Examples of the data samples \\n\", sms_spam_data_set.head(3), \"\\n\")\r\n",
    "print(\"Dimension of the data set:\\n\", sms_spam_data_set.shape, \"\\n\")\r\n",
    "print(\"Distribution of the data set:\\n\", sms_spam_data_set['Label'].value_counts(normalize=True), \"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Examples of the data samples \n",
      "   Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina... \n",
      "\n",
      "Dimension of the data set:\n",
      " (5572, 2) \n",
      "\n",
      "Distribution of the data set:\n",
      " ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Label, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Perform train/test split\r\n",
    "sms_texts, labels = sms_spam_data_set.SMS, sms_spam_data_set.Label\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "sms_texts_train, sms_texts_test, labels_train, labels_test = train_test_split(sms_texts, labels, test_size=0.2, random_state=123)\r\n",
    "\r\n",
    "sms_texts_train = sms_texts_train.reset_index(drop=True)\r\n",
    "labels_train = labels_train.reset_index(drop=True)\r\n",
    "\r\n",
    "sms_texts_test = sms_texts_test.reset_index(drop=True)\r\n",
    "labels_test = labels_test.reset_index(drop=True)\r\n",
    "\r\n",
    "print(\"Distribtuion of the training data set:\\n\", labels_train.value_counts(normalize=True),  labels_train.shape[0], \"\\n\")\r\n",
    "\r\n",
    "print(\"Distribtuion of the testing data set:\\n\", labels_test.value_counts(normalize=True), labels_test.shape[0], \"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Distribtuion of the training data set:\n",
      " ham     0.866726\n",
      "spam    0.133274\n",
      "Name: Label, dtype: float64 4457 \n",
      "\n",
      "Distribtuion of the testing data set:\n",
      " ham     0.86278\n",
      "spam    0.13722\n",
      "Name: Label, dtype: float64 1115 \n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Function to convert input sms texts to feature vectors using BoW representation\r\n",
    "def smsTextsToVectors(sms_texts):\r\n",
    "    sms_texts = sms_texts.str.replace('\\W', ' ') #Remove punctuation\r\n",
    "    sms_texts = sms_texts.str.lower()\r\n",
    "    sms_texts = sms_texts.str.split()\r\n",
    "\r\n",
    "    vocabulary = []\r\n",
    "    for sms in sms_texts:\r\n",
    "        for word in sms:\r\n",
    "            vocabulary.append(word)\r\n",
    "        \r\n",
    "    vocabulary = list(set(vocabulary))\r\n",
    "    \r\n",
    "    word_counts_per_sms = {unique_word: [0] * len(sms_texts) for unique_word in vocabulary}\r\n",
    "    \r\n",
    "    for index, sms in enumerate(sms_texts):\r\n",
    "        for word in sms:\r\n",
    "            word_counts_per_sms[word][index] += 1\r\n",
    "            \r\n",
    "    return word_counts_per_sms, vocabulary\r\n",
    "\r\n",
    "word_counts_per_sms, vocabulary  = smsTextsToVectors(sms_texts_train) \r\n",
    "x_train = pd.DataFrame(word_counts_per_sms)\r\n",
    "print(\"Features (the number of all possible words in the trainning data):\\n\", len(vocabulary), \"\\n\")\r\n",
    "\r\n",
    "training_data_set = pd.concat([labels_train, sms_texts_train, x_train], axis=1)\r\n",
    "print(\"Examples of the training data \\n\", training_data_set.head(3), \"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-4-10209bae6ee5>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sms_texts = sms_texts.str.replace('\\W', ' ') #Remove punctuation\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features (the number of all possible words in the trainning data):\n",
      " 7732 \n",
      "\n",
      "Examples of the training data \n",
      "   Label                                                SMS  88877  lark  \\\n",
      "0  spam  Double mins and txts 4 6months FREE Bluetooth ...      0     0   \n",
      "1   ham  Did you get any gift? This year i didnt get an...      0     0   \n",
      "2   ham  Ever green quote ever told by Jerry in cartoon...      0     0   \n",
      "\n",
      "   class  price  flag  accommodationvouchers  entrepreneurs  shoes  ...  rang  \\\n",
      "0      0      0     0                      0              0      0  ...     0   \n",
      "1      0      0     0                      0              0      0  ...     0   \n",
      "2      0      0     0                      0              0      0  ...     0   \n",
      "\n",
      "   closes  clip  happenin  pixels  300603t  wake  spoons  dungerees  figures  \n",
      "0       0     0         0       0        0     0       0          0        0  \n",
      "1       0     0         0       0        0     0       0          0        0  \n",
      "2       0     0         0       0        0     0       0          0        0  \n",
      "\n",
      "[3 rows x 7734 columns] \n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "x_train_spam = x_train[labels_train == 'spam']\r\n",
    "x_train_ham = x_train[labels_train == 'ham']\r\n",
    "\r\n",
    "#Estimate P(y=spam) and P(y=ham)\r\n",
    "p_spam = len(x_train_spam)/len(x_train)\r\n",
    "print(\"Our estimate of P(y=spam) is \", p_spam)\r\n",
    "\r\n",
    "p_ham = len(x_train_ham)/len(x_train)\r\n",
    "print(\"Our estimate of P(y=ham) is \", p_ham)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Our estimate of P(y=spam) is  0.13327350235584473\n",
      "Our estimate of P(y=ham) is  0.8667264976441552\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Initiate parameters\r\n",
    "theta_spam = {unique_word:0 for unique_word in vocabulary}\r\n",
    "theta_ham =  {unique_word:0 for unique_word in vocabulary}\r\n",
    "\r\n",
    "#Estimate the probability distribution of selecting each word\r\n",
    "# uncomment to implement the following\r\n",
    "m_spam=0\r\n",
    "m_ham = 0\r\n",
    "\r\n",
    "for word in vocabulary:\r\n",
    "    m_spam = m_spam + sum(x_train_spam[word])\r\n",
    "    m_ham = m_ham + sum(x_train_ham[word])\r\n",
    "\r\n",
    "for word in vocabulary:\r\n",
    "    # uncomment to implement the following\r\n",
    "    theta_spam[word] = sum(x_train_spam[word])/m_spam\r\n",
    "    \r\n",
    "    # uncomment to implement the following\r\n",
    "    theta_ham[word] = sum(x_train_ham[word])/m_ham\r\n",
    "    #MAP check whether on data-train has frequence 0 so we can assume confidence value\r\n",
    "    if(theta_spam[word] ==0):\r\n",
    "        theta_spam[word] = 1/(m_spam+m_ham)\r\n",
    "    if(theta_ham[word]==0):\r\n",
    "        theta_ham[word] = 1/(m_ham+m_spam)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#implment Naive Bayes classifier\r\n",
    "import re, math\r\n",
    "def textToVector(message):\r\n",
    "    message = re.sub('\\W', ' ', message) #Remove punctuation\r\n",
    "    message = message.lower().split()\r\n",
    "\r\n",
    "    vocabulary = []\r\n",
    "    for word in  message:\r\n",
    "        vocabulary.append(word)\r\n",
    "        \r\n",
    "    vocabulary = list(set(vocabulary))\r\n",
    "    \r\n",
    "    word_counts = {unique_word: 0 for unique_word in vocabulary}\r\n",
    "    \r\n",
    "    for word in message:\r\n",
    "            word_counts[word] += 1\r\n",
    "            \r\n",
    "    return word_counts, vocabulary\r\n",
    "\r\n",
    "def naive_bayes_classify(sms_text):\r\n",
    "    x_test, vocabulary_test = textToVector(sms_text)\r\n",
    "    #Navie Bayes Classification \r\n",
    "    p_spam_given_sms = np.log(p_spam)\r\n",
    "    p_ham_given_sms = np.log(p_ham)\r\n",
    "    for word in vocabulary_test:\r\n",
    "        if(word in (theta_spam)):\r\n",
    "            p_spam_given_sms += (x_test[word]*np.log(theta_spam[word]))\r\n",
    "        else:\r\n",
    "            p_spam_given_sms +=  (x_test[word]*np.log(1/(m_spam+m_ham))) #MAP condition when there no word in data train\r\n",
    "\r\n",
    "        if (word in (theta_ham)):\r\n",
    "            p_ham_given_sms += (x_test[word]*np.log(theta_ham[word]))\r\n",
    "        else:\r\n",
    "             p_ham_given_sms +=  (x_test[word]*np.log(1/(m_ham+m_spam))) #MAP condition when there no word in data train\r\n",
    "#     uncomment to implement the following\r\n",
    "\r\n",
    "    isSpam = True\r\n",
    "    if(p_spam_given_sms > p_ham_given_sms):\r\n",
    "        isSpam = True\r\n",
    "    else:\r\n",
    "        isSpam = False\r\n",
    "    return isSpam\r\n",
    "     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(naive_bayes_classify(\"WINNER!! This is the secret code to unlock the money: C3421.\"))\r\n",
    "print(naive_bayes_classify(\"Sounds good, Tom, then u there\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def score(sms_texts, labels):\r\n",
    "    mistakes = 0\r\n",
    "    for i, message in enumerate(sms_texts):\r\n",
    "        isSpam = naive_bayes_classify(message)\r\n",
    "        if isSpam and labels[i] != \"spam\":\r\n",
    "            mistakes += 1\r\n",
    "        elif not isSpam and labels[i] == \"spam\":\r\n",
    "            mistakes += 1\r\n",
    "    return (len(sms_texts)-mistakes)/len(sms_texts)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Calculate loss on training data\r\n",
    "print(\"Training accuracy:\", score(sms_texts_train, labels_train))\r\n",
    "#Calculate generalization loss\r\n",
    "print(\"Generalization accuracy:\", score(sms_texts_test, labels_test))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 0.9946152120260264\n",
      "Generalization accuracy: 0.9847533632286996\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"It's spam\" if naive_bayes_classify(\"Click here for more info\") else \"It's ham\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It's spam\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "7dc9b60826d74eb5607c37aaee63a43972728f09b483ccd1914805061130993f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}