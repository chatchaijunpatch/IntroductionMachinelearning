{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sms_spam_data_set = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "print(\"Examples of the data samples \\n\", sms_spam_data_set.head(3), \"\\n\")\n",
    "print(\"Dimension of the data set:\\n\", sms_spam_data_set.shape, \"\\n\")\n",
    "print(\"Distribution of the data set:\\n\", sms_spam_data_set['Label'].value_counts(normalize=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Perform train/test split\n",
    "sms_texts, labels = sms_spam_data_set.SMS, sms_spam_data_set.Label\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "sms_texts_train, sms_texts_test, labels_train, labels_test = train_test_split(sms_texts, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "sms_texts_train = sms_texts_train.reset_index(drop=True)\n",
    "labels_train = labels_train.reset_index(drop=True)\n",
    "\n",
    "sms_texts_test = sms_texts_test.reset_index(drop=True)\n",
    "labels_test = labels_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Distribtuion of the training data set:\\n\", labels_train.value_counts(normalize=True),  labels_train.shape[0], \"\\n\")\n",
    "\n",
    "print(\"Distribtuion of the testing data set:\\n\", labels_test.value_counts(normalize=True), labels_test.shape[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to convert input sms texts to feature vectors using BoW representation\n",
    "def smsTextsToVectors(sms_texts):\n",
    "    sms_texts = sms_texts.str.replace('\\W', ' ') #Remove punctuation\n",
    "    sms_texts = sms_texts.str.lower()\n",
    "    sms_texts = sms_texts.str.split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for sms in sms_texts:\n",
    "        for word in sms:\n",
    "            vocabulary.append(word)\n",
    "        \n",
    "    vocabulary = list(set(vocabulary))\n",
    "    \n",
    "    word_counts_per_sms = {unique_word: [0] * len(sms_texts) for unique_word in vocabulary}\n",
    "    \n",
    "    for index, sms in enumerate(sms_texts):\n",
    "        for word in sms:\n",
    "            word_counts_per_sms[word][index] += 1\n",
    "            \n",
    "    return word_counts_per_sms, vocabulary\n",
    "\n",
    "word_counts_per_sms, vocabulary  = smsTextsToVectors(sms_texts_train) \n",
    "x_train = pd.DataFrame(word_counts_per_sms)\n",
    "print(\"Features (the number of all possible words in the trainning data):\\n\", len(vocabulary), \"\\n\")\n",
    "\n",
    "training_data_set = pd.concat([labels_train, sms_texts_train, x_train], axis=1)\n",
    "print(\"Examples of the training data \\n\", training_data_set.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_spam = x_train[labels_train == 'spam']\n",
    "x_train_ham = x_train[labels_train == 'ham']\n",
    "\n",
    "#Estimate P(y=spam) and P(y=ham)\n",
    "p_spam = len(x_train_spam)/len(x_train)\n",
    "print(\"Our estimate of P(y=spam) is \", p_spam)\n",
    "\n",
    "p_ham = len(x_train_ham)/len(x_train)\n",
    "print(\"Our estimate of P(y=ham) is \", p_ham)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate parameters\n",
    "theta_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "theta_ham =  {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "#Estimate the probability distribution of selecting each word\n",
    "# uncomment to implement the following\n",
    "for word in vocabulary:\n",
    "    # uncomment to implement the following\n",
    "    theta_spam[word] = len(word)\n",
    "    # uncomment to implement the following\n",
    "    theta_ham[word] = len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implment Naive Bayes classifier\n",
    "import re, math\n",
    "def textToVector(message):\n",
    "    message = re.sub('\\W', ' ', message) #Remove punctuation\n",
    "    message = message.lower().split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for word in  message:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "    vocabulary = list(set(vocabulary))\n",
    "    \n",
    "    word_counts = {unique_word: 0 for unique_word in vocabulary}\n",
    "    \n",
    "    for word in message:\n",
    "            word_counts[word] += 1\n",
    "            \n",
    "    return word_counts, vocabulary\n",
    "\n",
    "def naive_bayes_classify(sms_text):\n",
    "    x_test, vocabulary_test = textToVector(sms_text)\n",
    "    print(x_test)\n",
    "    print(vocabulary_test)\n",
    "    # uncomment to implement the following\n",
    "    for word in theta_spam:\n",
    "        if(theta_spam[word] == x_test[word]):\n",
    "            print()\n",
    "    # p_ham_given_sms = ?\n",
    "\n",
    "#     print('Estimate of log(P(SPAM|message=',  sms_text, ')) =', p_spam_given_sms)\n",
    "#     print('Estimate of log(P(HAM|message=',  sms_text, ')) =', p_ham_given_sms)\n",
    "#     isSpam = True\n",
    "#     if(p_spam_given_sms > p_ham_given_sms):\n",
    "#         isSpam = True\n",
    "#     else:\n",
    "#         isSpam = False\n",
    "#     return isSpam\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(naive_bayes_classify(\"WINNER!! This is the secret code to unlock the money: C3421.\"))\n",
    "# print(naive_bayes_classify(\"Sounds good, Tom, then u there\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(sms_texts, labels):\n",
    "    mistakes = 0\n",
    "    for i, message in enumerate(sms_texts):\n",
    "        isSpam = naive_bayes_classify(message)\n",
    "        if isSpam and labels[i] != \"spam\":\n",
    "            mistakes += 1\n",
    "        elif not isSpam and labels[i] == \"spam\":\n",
    "            mistakes += 1\n",
    "    return (len(sms_texts)-mistakes)/len(sms_texts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate loss on training data\n",
    "print(\"Training accuracy:\", score(sms_texts_train, labels_train))\n",
    "#Calculate generalization loss\n",
    "print(\"Generalization accuracy:\", score(sms_texts_test, labels_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
